{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis.____ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw5Zz2NYEE-k"
      },
      "source": [
        "# 댓글 데이터 감성분석\n",
        "- Aurora3 기반 https://github.com/gyubok-lee/Aurora3\n",
        "- Google colaboratory 이용시 drive mount & cd 설정 필요\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJdmaAk1SqKz"
      },
      "source": [
        "\"\"\"\n",
        "cd /content/drive/MyDrive/경로설정\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFehu9X3RuLL"
      },
      "source": [
        "# konply 설치\n",
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psetTOI5RuBj"
      },
      "source": [
        "# module & package 가져오기\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import konlpy\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import font_manager, rc\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import urllib.request\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(-2, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQypLXv63Ef3"
      },
      "source": [
        "# 작업순서\n",
        "- input data 파일 형식 바꿔주기\n",
        "- test, train data 불러오기\n",
        "- 데이터 전처리 작업\n",
        "- 단어별로 감성점수 측정, 추정\n",
        "- 댓글 문장 별 감성분석\n",
        "- score 측점 결과 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOJRGWz_RmZg"
      },
      "source": [
        "\"\"\"\n",
        "- 파일 변환 -\n",
        "\n",
        "df = pd.read_excel('파일경로/변환 전 파일이름.xlsx')\n",
        "print(df)\n",
        "df.to_csv('변환 후 새로 생기는 파일이름.txt',index=True)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AMDzdUe7Y_j"
      },
      "source": [
        "# 영화제목 적어주기\n",
        "\n",
        "movie_name = \"#살아있다\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kxlbrTkScLw",
        "outputId": "a332547f-4e2f-490f-cb61-9c7e79a27e6f"
      },
      "source": [
        "df = pd.read_excel(f'data_xlsx/youtube_comments_{movie_name}.xlsx')\n",
        "print(df)\n",
        "df.to_csv(f'data_txt/youtube_comments_{movie_name}.txt',index=True, sep='\\t')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                comment  ...      videoId\n",
            "0                                          갓직히 라면은 진순이지  ...  wm06nhjoAQ8\n",
            "1                                           나만 재밌게 봤나.?  ...  wm06nhjoAQ8\n",
            "2     하..반도보고도 허무했는데..이것도 그런가요. <a href=\"http://www....  ...  wm06nhjoAQ8\n",
            "3       그런데 제가보기엔 괜찮은게 생존의 생각을 못하고 앞에보이는거만 보는이미지 괜찮았습니다  ...  wm06nhjoAQ8\n",
            "4                                               ㅈㄴ불편하넹?  ...  wm06nhjoAQ8\n",
            "...                                                 ...  ...          ...\n",
            "4840                                    나만 이노래가 ㅗ름 끼친가?  ...  YzS9h3T2bXY\n",
            "4841  이거 들으면서 학원갈 준비하면 완전 좀비랑 <br>싸우러 가려고 준비하는 기분..<...  ...  YzS9h3T2bXY\n",
            "4842                                           공부랑 싸우다니  ...  YzS9h3T2bXY\n",
            "4843                                               😆😆😆😆  ...  YzS9h3T2bXY\n",
            "4844                                             인정요ㅋㅋㅋ  ...  YzS9h3T2bXY\n",
            "\n",
            "[4845 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "HYsUb96hScGX",
        "outputId": "aad8180d-cc2d-46da-f911-b33ee89ad4f5"
      },
      "source": [
        "# 입력 데이터프레임은 다음과 같은 양식으로 통일할 것\n",
        "df = pd.read_table(f'data_txt/youtube_comments_{movie_name}.txt')\n",
        "#영화별로 총 댓글 수 다름 -> 자동화\n",
        "df = df.iloc[:,:] \n",
        "# 기존 row name을 data에 맞게 변경\n",
        "df = df[['videoId','comment']]\n",
        "df = df.rename(columns={\"videoId\": \"id\", \"comment\": \"sentence\"})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wm06nhjoAQ8</td>\n",
              "      <td>갓직히 라면은 진순이지</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wm06nhjoAQ8</td>\n",
              "      <td>나만 재밌게 봤나.?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wm06nhjoAQ8</td>\n",
              "      <td>하..반도보고도 허무했는데..이것도 그런가요. &lt;a href=\"http://www....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wm06nhjoAQ8</td>\n",
              "      <td>그런데 제가보기엔 괜찮은게 생존의 생각을 못하고 앞에보이는거만 보는이미지 괜찮았습니다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wm06nhjoAQ8</td>\n",
              "      <td>ㅈㄴ불편하넹?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4840</th>\n",
              "      <td>YzS9h3T2bXY</td>\n",
              "      <td>나만 이노래가 ㅗ름 끼친가?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4841</th>\n",
              "      <td>YzS9h3T2bXY</td>\n",
              "      <td>이거 들으면서 학원갈 준비하면 완전 좀비랑 &lt;br&gt;싸우러 가려고 준비하는 기분..&lt;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4842</th>\n",
              "      <td>YzS9h3T2bXY</td>\n",
              "      <td>공부랑 싸우다니</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4843</th>\n",
              "      <td>YzS9h3T2bXY</td>\n",
              "      <td>😆😆😆😆</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4844</th>\n",
              "      <td>YzS9h3T2bXY</td>\n",
              "      <td>인정요ㅋㅋㅋ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4845 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               id                                           sentence\n",
              "0     wm06nhjoAQ8                                       갓직히 라면은 진순이지\n",
              "1     wm06nhjoAQ8                                        나만 재밌게 봤나.?\n",
              "2     wm06nhjoAQ8  하..반도보고도 허무했는데..이것도 그런가요. <a href=\"http://www....\n",
              "3     wm06nhjoAQ8    그런데 제가보기엔 괜찮은게 생존의 생각을 못하고 앞에보이는거만 보는이미지 괜찮았습니다\n",
              "4     wm06nhjoAQ8                                            ㅈㄴ불편하넹?\n",
              "...           ...                                                ...\n",
              "4840  YzS9h3T2bXY                                    나만 이노래가 ㅗ름 끼친가?\n",
              "4841  YzS9h3T2bXY  이거 들으면서 학원갈 준비하면 완전 좀비랑 <br>싸우러 가려고 준비하는 기분..<...\n",
              "4842  YzS9h3T2bXY                                           공부랑 싸우다니\n",
              "4843  YzS9h3T2bXY                                               😆😆😆😆\n",
              "4844  YzS9h3T2bXY                                             인정요ㅋㅋㅋ\n",
              "\n",
              "[4845 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BuewPYDEE_K"
      },
      "source": [
        "# 데이터 전처리 및 토큰화 작업\n",
        "\n",
        "okt = konlpy.tag.Okt()\n",
        "\n",
        "def text_preprocess(x):\n",
        "    text=[]\n",
        "    \"\"\"\n",
        "    <br>, <a href~ > 등의 태그 제거 작업 추가 필요\n",
        "    \"\"\"\n",
        "    x = re.sub(\"<.+?>\",\"\",x)\n",
        "    a = re.sub('[^가-힣0-9a-zA-Z\\\\s]', '',x)\n",
        "    for j in a.split():\n",
        "        text.append(j)\n",
        "    return ' '.join(text)\n",
        "\n",
        "def tokenize(x):\n",
        "    text = []\n",
        "    tokens = okt.pos(x)\n",
        "    for token in tokens :\n",
        "        if token[1] == 'Adjective' or token[1]=='Adverb' or token[1] == 'Determiner' or token[1] == 'Noun' or token[1] == 'Verb' or 'Unknown':\n",
        "            text.append(token[0])\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "1nVp8kPOJm1F",
        "outputId": "f0bc33e6-60e5-4db7-cbdd-cdd147049ec8"
      },
      "source": [
        "# 잘 되었는지 확인\n",
        "\n",
        "tqdm.pandas()\n",
        "df['comment_cut'] = df['sentence'].apply(lambda x : text_preprocess(x))\n",
        "df['comment_cut'] = df['comment_cut'].progress_apply(lambda x: tokenize(x))\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4845/4845 [00:21<00:00, 227.86it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>comment_cut</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wm06nhjoAQ8</td>\n",
              "      <td>갓직히 라면은 진순이지</td>\n",
              "      <td>[갓, 직히, 라면, 은, 진, 순이, 지]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wm06nhjoAQ8</td>\n",
              "      <td>나만 재밌게 봤나.?</td>\n",
              "      <td>[나, 만, 재밌게, 봤나]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wm06nhjoAQ8</td>\n",
              "      <td>하..반도보고도 허무했는데..이것도 그런가요. &lt;a href=\"http://www....</td>\n",
              "      <td>[하반, 도보, 고도, 허무했는데이것도, 그런, 가요, 살아만, 있다, 인가요, 오...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wm06nhjoAQ8</td>\n",
              "      <td>그런데 제가보기엔 괜찮은게 생존의 생각을 못하고 앞에보이는거만 보는이미지 괜찮았습니다</td>\n",
              "      <td>[그런데, 제, 가보기엔, 괜찮, 은, 게, 생존, 의, 생각, 을, 못, 하고, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wm06nhjoAQ8</td>\n",
              "      <td>ㅈㄴ불편하넹?</td>\n",
              "      <td>[불편하, 넹]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4840</th>\n",
              "      <td>YzS9h3T2bXY</td>\n",
              "      <td>나만 이노래가 ㅗ름 끼친가?</td>\n",
              "      <td>[나, 만, 이, 노래, 가, 름, 끼친가]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4841</th>\n",
              "      <td>YzS9h3T2bXY</td>\n",
              "      <td>이거 들으면서 학원갈 준비하면 완전 좀비랑 &lt;br&gt;싸우러 가려고 준비하는 기분..&lt;...</td>\n",
              "      <td>[이, 거, 들으면서, 학원, 갈, 준비, 하면, 완전, 좀비, 랑, 싸우러, 가려...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4842</th>\n",
              "      <td>YzS9h3T2bXY</td>\n",
              "      <td>공부랑 싸우다니</td>\n",
              "      <td>[공부, 랑, 싸우다니]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4843</th>\n",
              "      <td>YzS9h3T2bXY</td>\n",
              "      <td>😆😆😆😆</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4844</th>\n",
              "      <td>YzS9h3T2bXY</td>\n",
              "      <td>인정요ㅋㅋㅋ</td>\n",
              "      <td>[인정, 요]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4845 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               id  ...                                        comment_cut\n",
              "0     wm06nhjoAQ8  ...                           [갓, 직히, 라면, 은, 진, 순이, 지]\n",
              "1     wm06nhjoAQ8  ...                                    [나, 만, 재밌게, 봤나]\n",
              "2     wm06nhjoAQ8  ...  [하반, 도보, 고도, 허무했는데이것도, 그런, 가요, 살아만, 있다, 인가요, 오...\n",
              "3     wm06nhjoAQ8  ...  [그런데, 제, 가보기엔, 괜찮, 은, 게, 생존, 의, 생각, 을, 못, 하고, ...\n",
              "4     wm06nhjoAQ8  ...                                           [불편하, 넹]\n",
              "...           ...  ...                                                ...\n",
              "4840  YzS9h3T2bXY  ...                           [나, 만, 이, 노래, 가, 름, 끼친가]\n",
              "4841  YzS9h3T2bXY  ...  [이, 거, 들으면서, 학원, 갈, 준비, 하면, 완전, 좀비, 랑, 싸우러, 가려...\n",
              "4842  YzS9h3T2bXY  ...                                      [공부, 랑, 싸우다니]\n",
              "4843  YzS9h3T2bXY  ...                                                 []\n",
              "4844  YzS9h3T2bXY  ...                                            [인정, 요]\n",
              "\n",
              "[4845 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_5Pd7DIScCT"
      },
      "source": [
        "sent_dic = pd.read_csv('SentiWord_Dict.txt',sep = '\\t',header=None)\n",
        "sent_dic.iloc[14850,0]='갈등'\n",
        "\n",
        "pos_dic = sent_dic[sent_dic[1]>0]\n",
        "neg_dic = sent_dic[sent_dic[1]<0]\n",
        "neu_dic = sent_dic[sent_dic[1]==0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuC83E8qEE_r"
      },
      "source": [
        "# class 선언으로 한번에 작업 처리\n",
        "\n",
        "class Aurora3:\n",
        "    \n",
        "    def __init__(self, df,sent_dic):\n",
        "        self.df = df\n",
        "        self.okt = konlpy.tag.Okt()\n",
        "        self.sent_dic = sent_dic\n",
        "        \n",
        "    def get_df(self):# 최종 결과 반환\n",
        "        #print(\"문장 토큰화 중입니다...\")\n",
        "        #self.tokenizer_run()\n",
        "        \n",
        "        print(\"감성사전 업데이트 중입니다...\")\n",
        "        self.expand_sent_dic()\n",
        "        \n",
        "        print(\"문장 감성분석 중입니다....\")\n",
        "        self.sent_analyze()\n",
        "        return self.df\n",
        "    \"\"\"    \n",
        "    def tokenizer_run(self): # 텍스트 전처리 & 토큰화\n",
        "        tqdm.pandas()\n",
        "        \n",
        "        def text_preprocess(x): \n",
        "            text=[]\n",
        "            \n",
        "            x1 = re.sub(\"<.+?>\",\"\",x)\n",
        "            a = re.sub('[^가-힣0-9a-zA-Z\\\\s]', '',x1)\n",
        "            for j in a.split():\n",
        "                text.append(j)\n",
        "            return ' '.join(text)\n",
        "\n",
        "        def tokenize(x):\n",
        "            text = []\n",
        "            tokens = self.okt.pos(x)\n",
        "            for token in tokens :\n",
        "                if token[1] == 'Adjective' or token[1]=='Adverb' or token[1] == 'Determiner' or token[1] == 'Noun' or token[1] == 'Verb' or 'Unknown':\n",
        "                    text.append(token[0])\n",
        "            return text\n",
        "\n",
        "        self.df['comment_cut'] = self.df['sentence'].apply(lambda x : text_preprocess(x))\n",
        "        self.df['comment_cut'] = self.df['comment_cut'].progress_apply(lambda x: tokenize(x))\n",
        "    \"\"\"\n",
        "    def expand_sent_dic(self):\n",
        "        sent_dic = self.sent_dic\n",
        "        \n",
        "        def make_sent_dict(x) :\n",
        "            pos=[]\n",
        "            neg=[]\n",
        "            tmp={}\n",
        "\n",
        "            for sentence in tqdm(x):\n",
        "                for word in sentence :\n",
        "                    target = sent_dic[sent_dic[0]==word]\n",
        "                    if len(target)==1: # 기존에 있는 단어라면 그대로 사용\n",
        "                        score = float(target[1])\n",
        "                        if score > 0:\n",
        "                            pos.append(word)\n",
        "                        elif score < 0:\n",
        "                            neg.append(word)                \n",
        "                    tmp[word] = {'W':0,'WP':0,'WN':0} # 감성사전 구성\n",
        "            pos = list(set(pos))\n",
        "            neg = list(set(neg))\n",
        "\n",
        "            for sentence in tqdm(x):\n",
        "                for word in sentence :\n",
        "                    tmp[word]['W'] += 1 # 빈도 수\n",
        "                    for po in pos :\n",
        "                        if po in sentence:\n",
        "                            tmp[word]['WP'] += 1 # 긍정단어과 같은 문장 내 단어일 때\n",
        "                            break\n",
        "                    for ne in neg:\n",
        "                        if ne in sentence:\n",
        "                            tmp[word]['WN'] += 1 # 부정단어와 같은 문장내 단어일 때\n",
        "                            break\n",
        "            return pos, neg, pd.DataFrame(tmp)\n",
        "        \n",
        "        def make_score_dict(d,p,n):\n",
        "            N=sum(d.iloc[0,::])\n",
        "            pos_cnt=sum(d.loc[::,p].iloc[0,::])\n",
        "            neg_cnt=sum(d.loc[::,n].iloc[0,::])\n",
        "\n",
        "            trans =d.T\n",
        "            trans['neg_cnt']=neg_cnt\n",
        "            trans['pos_cnt']=pos_cnt\n",
        "            trans['N']=N\n",
        "\n",
        "            trans['MI_P']=np.log2(trans['WP']*trans['N']/trans['W']*trans['pos_cnt'])\n",
        "            trans['MI_N']=np.log2(trans['WN']*trans['N']/trans['W']*trans['neg_cnt'])\n",
        "            trans['SO_MI']=trans['MI_P'] - trans['MI_N']\n",
        "\n",
        "            trans = trans.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
        "            trans = trans.sort_values(by=['SO_MI'],ascending=False)\n",
        "            return trans\n",
        "        \n",
        "        def update_dict(d):\n",
        "            add_Dic = {0:[],1:[]}\n",
        "            for i in d.T.items():\n",
        "                if i[0] not in list(sent_dic[0]):\n",
        "                    if len(i[0]) > 1:\n",
        "                        add_Dic[0].append(i[0])\n",
        "                        add_Dic[1].append(i[1]['SO_MI'])\n",
        "\n",
        "            add_Dic=pd.DataFrame(add_Dic)\n",
        "            Sentiment=pd.merge(sent_dic,add_Dic,'outer')\n",
        "            return Sentiment\n",
        "        \n",
        "        self.pos, self.neg, self.new_dict = make_sent_dict(self.df['comment_cut'].values)\n",
        "        \n",
        "        self.t_dict = make_score_dict(self.new_dict,self.pos,self.neg)\n",
        "        self.t_dict['SO_MI'] = scaler.fit_transform(self.t_dict['SO_MI'].values.reshape(-1,1))\n",
        "       \n",
        "        self.add_dict =update_dict(self.t_dict)\n",
        "    \n",
        "    def sent_analyze(self): # 데이터 감성분석\n",
        "        tqdm.pandas()\n",
        "        \n",
        "        def get_cnt(x):\n",
        "            cnt = 0\n",
        "            for word in list(set(x)):\n",
        "                target = self.add_dict[self.add_dict[0]==word]\n",
        "                if len(target)==1:\n",
        "                    cnt += float(target[1])\n",
        "            return cnt\n",
        "\n",
        "        def get_ratio(x): # log로 score 정규화\n",
        "            score = x['score']\n",
        "            length = np.log10(len(x['comment_cut']))+1\n",
        "            try:\n",
        "                ratio= round(score/length,2)\n",
        "            except:\n",
        "                ratio = 0\n",
        "            return ratio\n",
        "        \n",
        "        tqdm.pandas()\n",
        "        self.df['score']= self.df['comment_cut'].progress_apply(lambda x : get_cnt(x))\n",
        "        self.df['ratio'] = self.df.apply(lambda x: get_ratio(x), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTuvUW1RSP_T"
      },
      "source": [
        "# 감성분석 점수 도출\n",
        "\n",
        "test = Aurora3(df,sent_dic)\n",
        "res = test.get_df()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pebzpTxXEE_v"
      },
      "source": [
        "# score 결과 파일로 저장\n",
        "\n",
        "score_res = pd.DataFrame(res)\n",
        "score_res.to_csv(f\"/content/drive/MyDrive/파일경로/score_youtube_comments_{movie_name}.csv\", header=True, index=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}